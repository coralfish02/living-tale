---
title: "キャラクターが勝手に動き出す物語生成AI「Living Tale」を作った"
emoji: "📖"
type: "idea"
topics: ["GoogleCloud", "Gemini", "AI", "Python", "gch4"]
published: true
---

## 🎬 はじめに：創作の「孤独」と「予定調和」を壊す

こんにちは！[**第4回 Agentic AI Hackathon with Google Cloud**](https://zenn.dev/hackathons/google-cloud-japan-ai-hackathon-vol4) に参加している、チーム「**ADS'25**」です。

私たちは**非エンジニアの社会人大学院生4人**で構成されたチームです。エンジニアリングのバックグラウンドがないからこそ、「**技術を使って何を届けられるか**」というユーザー視点を大切にしながら開発に取り組みました。

小説や脚本を書く作業は、孤独で過酷です。そして何より、作者自身が結末を知っているため、**「自分自身の想像を超える展開（サプライズ）」に出会えない**というジレンマがあります。

> 「もし、物語を紡ぐ語り手さえ知らない"本音"を、キャラクターたちが独自に抱えていたら？」

**Living Tale**は、そんなクリエイターの夢想を、**Gemini 2.0 Flash**のマルチエージェントシステムによって実現したプロダクトです。

**「書く（Write）」のではなく、環境を与えて「育てる（Grow）」**——新しい創作体験「**Gardening Storytelling**」を提案します。

:::message
🌐 **デモURL**: https://living-tale-551115298648.us-central1.run.app/
📦 **リポジトリ**: https://github.com/coralfish02/living-tale
:::

### Living TaleのUI

![Living Tale メイン画面 — キャラクター生成・起承転結の進行・AIからの提案チップが一画面に集約されている](/images/living-tale-top.png)
*▲ Living Taleのメイン画面。テーマを入力するだけでキャラクターが自動生成され、起承転結の各フェーズでAIからの提案（黄色チップ）を選びながら物語を育てていく。*

---

## 📌 開発背景と課題

### 創作における「構造的に超えられない壁」

キャラクターがどう動くかを設計する——物語づくりで最も重い工程です。

なぜ重いのか？ **すべてのキャラクターの思考を、たった1人の作者の頭で回さなければならないから**です。AはBの裏の動機を知らないはずなのに、作者はすべてを知っている。この構造がある限り、どれだけプロットを練っても**物語は作者の想像の範囲を超えられません**。

つまり創作には、時間やスキル以前に**「1人で全員を演じる」という原理的な限界**があるのです。

### ターゲット①：プロのクリエイター（週刊連載漫画家）

イメージしやすい例として**「週刊連載漫画家」**を取り上げます。漫画制作は一般に以下のように分解できます：

```
①ストーリー設計 → ②プロット設計 → ③ネーム → ④ペン入れ → ⑤仕上げ
```

このうち**①ストーリー設計〜②プロット設計**の工程は、毎週膨大な時間を消費します。Living Taleは、まさにこの探索負荷を下げるためのAIエージェントとして開発しました。

### ターゲット②：すべての「書く人」——「発信の民主化」の次に来るもの

Living Taleが見据えるのはプロの漫画家だけではありません。

noteの会員数は700万人を超え、小説家になろう・カクヨムの投稿作品は100万作品を超えています。**「発信の民主化」はすでに起きました**。誰もがnoteやSNSで文章を世に出せる時代です。

しかし、「発信できる」ことと「物語を創れる」ことの間には、まだ大きな溝があります。多くの人がキャラクターを作っても動かし方がわからず、途中で詰まり、プロのような構成力がないと面白い話は書けないと感じています。

この壁の正体は、スキル不足ではありません。先に述べた**「1人で全員の頭を回す」という構造的な限界**そのものです。プロであっても苦しむこの制約が、初心者にとってはなおさら高い壁になっている——ただそれだけのことです。

つまり、次に来るのは**「創作の民主化」**です。そしてそのカギは、「書く技術を教える」ことではなく、**「そもそも1人で全員を演じなくてよくする」**というパラダイムシフトにあります。

Living Taleは、このシフトを実現します。テーマを1行入力するだけで、**独立したAIエージェントがキャラクターとして自律的に動き出す**。ユーザーは全員の思考を回す必要がなく、方向性を示すだけで起承転結のある物語が生まれる。noteで文章を発信する人が「プロットの壁打ち相手」として使うことも、脚本家が「キャラクター同士の化学反応」を探索する実験場として使うこともできます。

:::message alert
**ペインまとめ**
- 🔴 **プロ**: キャラクターのシミュレーションに膨大な時間がかかる
- 🔴 **プロ**: 作者自身が結末を知っているため「予定調和」に陥りやすい
- 🔴 **全員**: 1人で行う作業のため、壁打ち相手がいない
- 🔴 **一般**: プロット構成の技術がなく、創作の最初の一歩が踏み出せない
- 🔴 **一般**: noteやSNSで発信したいが、物語を「書ける」自信がない
:::

---

## 💡 ソリューション：Living Taleとは

Living Taleは、**語り手エージェントが物語を紡ぎ、各キャラクターエージェントがその裏で独自の内心を生成する——この「表と裏の分離」から予定調和を壊す物語生成AIシステム**です。

### 「ChatGPTに物語を書かせる」のとは何が違うのか？

ここで、多くの方が疑問に思うであろうことに先にお答えします。

> 「ChatGPTやClaudeに『物語を書いて』と頼めば、もう物語は作れるのでは？」

結論から言うと、**まったく異なるアプローチ**です。

**普通のAIチャット**（ChatGPT、Claude、Geminiへの直接プロンプト）で物語を書かせると、こうなります：

- 🤖 **単一のAIが「全知全能の作者」として振る舞う**
- 結果として、すべてのキャラクターが**同じ「頭」で考え、同じ文体で話す**
- 物語の展開も1つのモデルが「ありがちなパターン」から選ぶため、**予定調和に陥りやすい**
- キャラクターに「裏の目的」を持たせても、同じAIが全員を操るため**本当の意味での駆け引きが生まれない**

Living Taleのアプローチはこれとは根本的に違います：

- 🎭 **語り手エージェントが物語を紡ぎ、各キャラクターの内心は独立したエージェントが生成する**——語り手が描いた行動と、キャラクターが独自に抱く本音のあいだに、意図せぬズレが自然に生まれる
- 🔀 **語り手さえ知らない「裏の感情」が物語に奥行きを与える**——内心エージェントは自分の性格・目的しか知らないため、予定調和に陥りようがない
- 📖 **語り手エージェントが第三者視点で俯瞰する**——全キャラクターの設定を把握した上で、セリフ・行動・心理を織り交ぜた小説風の描写を生成する

| | 普通のAIチャット | 既存のAI執筆支援ツール | **Living Tale** |
|---|---|---|---|
| **構造** | 単一AI | 単一AI + テンプレート | **マルチエージェント** |
| **キャラクター** | 全員が同じ「頭」 | プロフィール設定は可能 | **独立した人格・目的を持つ** |
| **展開の予測可能性** | 予定調和 | ほぼ予定調和 | **創発的・予測不能** |
| **キャラの内面** | 表面的 | 表面的 | **表と裏の二重構造** |
| **物語への介入** | プロンプトで全制御 | テンプレートに沿う | **方向性だけ指示、展開はAIに委ねる** |
| **ユーザーの役割** | 「指示する人」 | 「穴埋めする人」 | **「環境を与えて育てる人」** |

:::message
**たとえるなら：**
- 普通のAIチャット → **1人の作家に「全部書いて」と頼む**（セリフも内心も同じ頭が書く）
- Living Tale → **語り手（AI）が舞台を描き、役者（キャラクターAI）が語り手の知らないところで本音を抱える「二重構造の劇」**

語り手が描いた場面の裏側で、キャラクターが思いもよらない感情を抱えている——その"ズレ"こそが、予定調和を壊す鍵なのです。
:::

---

## 🌟 Living Taleの5つのコア機能

### 1. Dual-Layer（表と裏）システム

語り手エージェントが物語（セリフ・行動）を生成し、各キャラクターの**内心は独立したAIエージェント**が自身の性格・目的のみをもとに生成します。この分離が二重構造を生みます：

- **🗣️ 表の発言・行動**：他のキャラクターに見える公的なペルソナ
- **💭 裏の思考**：読者にだけ見える隠された動機・本音

```
【タクミ】タクミは帳簿を開きながら、真剣な表情で言った。
「予算の件、調べさせてもらうよ」
💭 タクミの内心: 誰が使い込んだのか、必ず見つける

【アヤ】アヤは顔色を変えながら答えた。
「え、そうなの？もう一度確認させてください」
💭 アヤの内心: やばい、気づかれた。どうしよう...
💭 タクミの内心: アヤの反応がおかしい...まさか？
```

この構造により、**読者は「本当は何を考えているのか」を知りながら会話を追う**という、独特の緊張感を体験できます。

### 2. 全キャラクターの内心同時表示

従来の物語では、視点キャラクターの内心しか見えませんでした。Living Taleでは、**全員の本音が同時に見える**という新しい体験を提供します。

- 人間関係の複雑さをリアルタイムで可視化
- 情報の非対称性による緊張感の演出
- 「群像劇」を読む新しい楽しみ方

### 3. インタラクティブな起承転結 + AIサジェスト

ユーザーが**各フェーズ（起承転結）で方向性を指示可能**です：

| フェーズ | 役割 | ユーザーの操作 |
|---|---|---|
| **起** | 状況設定 | 初期状況を確認し、展開の希望を入力 |
| **承** | 展開 | 関係性の発展方向を指示 |
| **転** | 転換 | 転換点の方向性を提案 |
| **結** | 結末 | 結末への希望を伝える |

ここで重要なのが、**「何を入力すればいいかわからない」問題**を解決する仕組みです。

各フェーズの開始時に、**AIが物語の流れを分析し、「次に加えると面白くなる展開」を3つ自動提案**します。ユーザーはチップ（ボタン）をクリックするだけで方向性を入力できます。

![AIからの提案チップのUI](/images/living-tale-suggest.png)
*▲ 実際のUI画面。「起」フェーズで「AI、突然暴走」「まさかのバグ発覚」「謎の参加者現る」の3つが提案され、クリックするだけでテキストエリアに自動入力される。*

これにより、3つの選択肢が生まれます：

1. **AIの提案をそのまま使う** → チップをクリックして「次へ進む」
2. **自分で自由に入力する** → テキストエリアに書いて「次へ進む」
3. **AIに完全に任せる** → 空欄のまま「次へ進む」

創作のプロは自分の意図を自由入力し、初心者はAIの提案をガイドとして活用する——**スキルレベルを問わず、誰でも物語を「育てる」体験ができる**設計です。

### 4. AIサジェスト：「次にどうする？」をAIが提案

各フェーズの開始時に、AIが物語の流れを分析し、**「次に加えると面白くなる展開」を3つ自動提案**します。提案はチップ（ボタン）として表示され、クリックするだけで方向性を入力できます。

この機能が、先述の「創作の民主化」において重要な役割を果たします。**プロットの組み方を知らなくても、AIの提案を選ぶだけで物語の舵取りに参加できる**のです。もちろん、プロのクリエイターは提案を無視して自分の意図を自由入力することもできます。

### 5. 小説風の地の文生成

会話劇ではなく、**小説として読める物語**を生成します。第三者視点の語り手エージェントが、セリフと行動・心理描写を織り交ぜた地の文を出力します。

---

## 🏗️ システムアーキテクチャ

### 技術スタック

| レイヤー | 技術 |
|---|---|
| **Frontend** | HTML / CSS / JavaScript（バニラ） |
| **Backend** | Python 3.11 / Flask |
| **AI Model** | Vertex AI **Gemini 2.0 Flash** (`gemini-2.0-flash-001`) |
| **画像生成** | **Imagen 3** (`imagen-3.0-generate-001`) |
| **Infra** | **Google Cloud Run**（サーバーレス） |
| **Container** | Docker / Container Registry |
| **Server** | Gunicorn（Workers: 1, Threads: 8） |

### アーキテクチャ図

```mermaid
graph TB
    subgraph "ユーザー（ブラウザ）"
        UI[Living Tale UI<br/>HTML/CSS/JS]
    end

    subgraph "Google Cloud Run"
        Flask[Flask App<br/>Python 3.11 / Gunicorn]
        Session[Session Manager<br/>セッション管理]
        PhaseGen[Phase Generator<br/>起承転結フェーズ制御]
    end

    subgraph "Vertex AI"
        CharGen[Character Agent<br/>キャラクター生成]
        Narrator[Narrator Agent<br/>語り手エージェント]
        InnerGen[Inner Thought Agent<br/>内心生成エージェント]
        Summary[Summary Agent<br/>要約生成]
        Imagen[Imagen 3<br/>ストーリーイメージ生成]
    end

    UI -->|"POST /start<br/>テーマ入力"| Flask
    UI -->|"POST /continue<br/>方向性指示"| Flask
    UI -->|"GET /status/:id<br/>ポーリング"| Flask
    Flask --> Session
    Session --> PhaseGen
    PhaseGen -->|"gemini-2.0-flash-001"| CharGen
    PhaseGen -->|"gemini-2.0-flash-001"| Narrator
    PhaseGen -->|"gemini-2.0-flash-001"| InnerGen
    PhaseGen -->|"gemini-2.0-flash-001"| Summary
    PhaseGen -->|"imagen-3.0-generate-001"| Imagen

    style UI fill:#E3F2FD
    style Flask fill:#FFF3E0
    style CharGen fill:#E8F5E9
    style Narrator fill:#E8F5E9
    style InnerGen fill:#E8F5E9
    style Summary fill:#E8F5E9
    style Imagen fill:#FCE4EC
```

### Dual-Layer Multi-Agent Systemの構造

```mermaid
graph LR
    subgraph "Control"
        User[ユーザー<br/>方向性指示]
    end

    subgraph "Layer 1: 物語生成"
        NarratorA[語り手Agent<br/>全キャラの設定を把握<br/>第三者視点で描写]
    end

    subgraph "Layer 2: 内心生成（独立）"
        CA1[キャラA Agent<br/>自分の性格・目的のみ]
        CA2[キャラB Agent<br/>自分の性格・目的のみ]
    end

    subgraph "起承転結"
        KI[起] --> SHO[承] --> TEN[転] --> KETSU[結]
    end

    User -->|各フェーズで介入| NarratorA
    NarratorA -->|物語テキスト| CA1 & CA2
    NarratorA --> KI
    CA1 & CA2 -.->|内心を付与| KI

    style NarratorA fill:#FFF8E1
    style CA1 fill:#FFEBEE
    style CA2 fill:#E8EAF6
```

### なぜCloud Runを選んだのか

| 選定理由 | 詳細 |
|---|---|
| **サーバーレス** | トラフィックがないときはコスト $0。ハッカソンデモに最適 |
| **長時間リクエスト対応** | `--timeout 0`（タイムアウト無制限）で物語生成の長時間処理に耐える |
| **スケーラビリティ** | 同時接続が増えても自動スケーリング |
| **Vertex AI連携** | 同じGCP上でIAMベースの認証がシームレス |

---

## 🔧 技術的な工夫・実装のポイント

### 1. プロンプトエンジニアリング：二層構造のエージェント設計

Living Taleの心臓部は、**語り手（Narrator）と内心生成を分離した二層のプロンプト設計**です。

物語の本文は**語り手エージェント**が全キャラクターの情報を持って第三者視点で生成し、各キャラクターの**内心だけは独立したエージェント**が自身の性格・目的のみをもとに生成します。

```python
# 内心生成プロンプト（web_echo_interactive.py）
# ★ 各キャラクターは自分の性格・目的しか知らない
inner_prompt = f"""
以下の場面における{agent['name']}の内心を1文で表現してください。

場面: {msg['narrative']}

あなたは{agent['name']}です。
性格: {[c for c in session['characters'] if c['name'] == agent['name']][0]['public_persona']}
目的: {[c for c in session['characters'] if c['name'] == agent['name']][0]['secret_goal']}

JSON形式で出力:
{{"inner_thought": "内心の考え（1文）"}}
"""
```

**ポイント：**
- **内心エージェントは自分の性格・目的しか知らない**ため、語り手が描写した「表の行動」と「裏の本音」にズレが自然に生まれる
- **出力形式をJSON強制**することで、後続処理でのパースを安定化
- **「表の性格」と「裏の目的」**を分離して渡すことで、Dual-Layer構造を実現

### 2. 第三者視点の語り手エージェント

**語り手（Narrator）エージェント**は、キャラクター個別視点ではなく、第三者視点で物語全体を俯瞰する小説風の描写を生成します。語り手は全キャラクターの性格・目的を知っているため、表面上の行動に裏の意図がにじむ描写が自然に生まれます。

```python
# 語り手エージェントのプロンプト（web_echo_interactive.py）
narrator_instruction = f"""
あなたは小説の語り手です。
登場人物2人が会話・行動する場面を、第三者視点の小説風地の文で描写してください。

登場人物:
{char_profiles}

【重要ルール】
- 必ず{char_names[0]}と{char_names[1]}の両方を登場させること
- どちらか一方の視点ではなく、客観的な第三者視点で描写すること
- セリフと行動・心理描写を織り交ぜること
- 読みやすく、自然な文章で描写すること
- 文頭は「その日、」「カフェの中で、」など情景から始めること

出力形式（JSON）:
{{
  "narrative": "第三者視点の地の文（両キャラクターが登場する自然な文章）",
  "inner_thought": "この場面全体の雰囲気や核心を1文で"
}}
必ずJSON形式のみで出力してください。
"""
```

**こだわり：**
- `「文頭は情景から始めること」`——これにより、「〇〇は言った」の連続を避け、小説的な文体を安定させています
- `「客観的な第三者視点で描写すること」`——一方のキャラクターに寄りすぎない中立的な描写を確保
- 両キャラクターを必ず登場させるルールにより、片方だけのモノローグに陥ることを防止

### 3. レート制限への徹底対策

Gemini APIの無料枠（10 RPM）を考慮し、**指数バックオフ + 安全待機**を組み合わせた堅牢なリトライ機構を実装しています。

```python
def call_with_retry(model, prompt, max_retries=5, initial_wait=60):
    """レート制限対策付きAPI呼び出し"""
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            if "429" in str(e) or "Resource exhausted" in str(e):
                wait_time = initial_wait * (attempt + 1)
                # 60秒 → 120秒 → 180秒 → 240秒 → 300秒
                print(f"[WARN] レート制限検知。{wait_time}秒待機...")
                time.sleep(wait_time)
            else:
                if attempt == max_retries - 1:
                    raise
                time.sleep(5)
    raise Exception("API呼び出し失敗")
```

さらに、**各APIコール間に8秒の安全待機**を挟むことで、10 RPM制限に安定的に収まるよう設計しています：

```python
time.sleep(8)  # ★安全のための待機 (10 RPM対策)
```

### 4. 非同期セッション管理とポーリング

物語生成は1フェーズあたり数十秒かかるため、**非同期処理 + フロントエンドからのポーリング**で「待ち」のUXを実現しています。

```python
# バックエンド: スレッドで非同期生成
def init_session():
    result = generate_phase(session_id, 'start')
    sessions[session_id].update(result)
    sessions[session_id]['status'] = 'ready'

thread = threading.Thread(target=init_session, daemon=True)
thread.start()
return jsonify({"session_id": session_id, "status": "initializing"})
```

```javascript
// フロントエンド: 2秒間隔でポーリング
statusCheckInterval = setInterval(async () => {
    const response = await fetch(`/status/${sessionId}`);
    const data = await response.json();
    
    if (data.status === 'ready') {
        clearInterval(statusCheckInterval);
        onSessionReady(data);
    } else if (data.status === 'generating') {
        showStatus('', 'generating');  // ローディングUI表示
    }
}, 2000);
```

### 5. AIサジェスト：「次の展開」を自動提案する仕組み

各フェーズ遷移時にAIが提案を自動生成する仕組みは、**専用のエンドポイント `/suggestions/<session_id>`** で実装しています。

```python
@app.route('/suggestions/<session_id>')
def suggestions(session_id):
    """次のフェーズへの方向性提案を返す（AIで生成）"""
    session = sessions.get(session_id)
    if not session:
        return jsonify({"error": "セッションが見つかりません"}), 404

    # すでに提案がある場合はキャッシュを返す
    phase = session.get('current_phase', 'ki')
    cache_key = f'suggestions_{phase}'
    if session.get(cache_key):
        return jsonify({"suggestions": session[cache_key]})

    # Geminiで提案をバックグラウンド生成
    def generate_suggestions():
        generator = GenerativeModel("gemini-2.0-flash-001")
        conversation = session.get('conversation', [])
        recent = conversation[-2:] if conversation else []
        story_so_far = "\n".join([m['narrative'] for m in recent])

        text = call_with_retry(generator, f"""
テーマ: {session['theme']}
現在のフェーズ: {phase_label}

【これまでの物語】
{story_so_far}

次の「{phase_label}」フェーズに加えると面白くなる展開を3つ提案してください。
各提案は15文字以内の短い一文にしてください。

JSON形式で出力:
{{"suggestions": ["提案1", "提案2", "提案3"]}}
""")
        data = json.loads(extract_json(text))
        session[cache_key] = data.get('suggestions', [])

    thread = threading.Thread(target=generate_suggestions, daemon=True)
    thread.start()
    return jsonify({"suggestions": session.get(cache_key, [])})
```

**設計のポイント：**

- **フェーズごとのキャッシュ**（`suggestions_ki`, `suggestions_sho` ...）により、同じフェーズでの再リクエストでAPIコールを節約
- **バックグラウンド生成** + フロントエンドからの**ポーリングリトライ**（2秒間隔）で、フェーズ遷移のUI表示と並行して提案を準備
- 提案プロンプトには**これまでの物語の文脈**を含めるため、「物語の流れに沿った、それでいて意外性のある提案」が生成される
- **15文字以内**の制約により、チップUIに収まる短い提案に統一

```javascript
// フロントエンド: フェーズ遷移時に自動で提案を取得
function updateDirectionLabel() {
    label.textContent = `「${phaseName}」フェーズで次の要素を加える...`;
    loadSuggestions();  // ← フェーズが切り替わるたびに提案を取得
}

async function loadSuggestions() {
    const response = await fetch(`/suggestions/${sessionId}`);
    const data = await response.json();
    const suggestions = data.suggestions || [];

    if (suggestions.length === 0) {
        setTimeout(loadSuggestions, 2000);  // まだ生成中ならリトライ
        return;
    }

    // チップUIとして表示、クリックでテキストエリアに自動入力
    suggestions.forEach(suggestion => {
        chip.textContent = suggestion;
        chip.onclick = () => {
            document.getElementById('directionInput').value = suggestion;
        };
    });
}
```

この仕組みにより、ユーザーは**「何を入力すればいいかわからない」というハードルを感じることなく**、AIと一緒に物語を育てていくことができます。

### 6. Imagen 3によるストーリーイメージの自動生成

物語完成後、起承転結の全フェーズを通して**最も印象的なシーンを1枚のイラストとして自動生成**する機能を実装しました。

```python
# Step1: Geminiでストーリー全体を要約 → 英語プロンプトに変換
summary_prompt = f"""
以下の起承転結のストーリー全体から、最も印象的なシーンを
画像生成用に30語以内の英語で要約してください。
キャラクターの動作、表情、場所のみ。セリフは不要。

ストーリー全体:
{story_text[:500]}
キャラクター: {char_desc}
"""
scene_summary = call_with_retry(generator, summary_prompt)
image_prompt = f"Anime style illustration: {scene_summary}. No text, no speech bubbles."

# Step2: Imagen 3で1枚のイメージイラストを生成
imagen = ImageGenerationModel.from_pretrained("imagen-3.0-generate-001")
images = imagen.generate_images(
    prompt=image_prompt,
    number_of_images=1,
)
```

**ポイント：**
- **Geminiをプロンプト要約器として活用**：起承転結の全ストーリーから最も印象的なシーンを30語の英語に凝縮
- 物語表示をブロックしないよう**別スレッドで非同期生成**
- 3回のリトライ機構で画像生成の安定性を確保

### 7. UIの工夫

フロントエンドでは、物語体験を最大化するために以下の工夫を施しています：

- **黄×黒のモノクロームUI**：全体を `#FFD700`（ゴールド）× 黒で統一し、フェーズバッジとプログレスバーで起承転結の進行を視覚化
- **内心の折りたたみ表示**：ネタバレを避けたい場合にトグルで隠せる
- **ダークモード対応**：CSS変数によるテーマ切り替え
- **プログレスバー**：物語進行の可視化（起:25% → 承:50% → 転:75% → 結:100%）

---

## 📊 コスト

| 項目 | 詳細 |
|---|---|
| **Gemini 2.0 Flash** | 1ストーリーあたり約10回のAPIコール |
| **Imagen 3** | 1枚のストーリーイメージ生成 |
| **Cloud Run** | リクエスト時のみ起動（アイドル時 $0） |
| **1回あたりの推定コスト** | **約 $0.05〜0.10** |

---

## 🔮 今後の展望

Living Taleはまだ進化の途中です。以下の機能を予定しています：

1. **3人以上のマルチエージェント対応** — より複雑な群像劇の生成
2. **Trickster Engine** — 予定調和を意図的に壊すランダムイベントの導入
3. **音声合成連携** — キャラクターボイスの自動生成（Cloud Text-to-Speech）
4. **ユーザー介入の強化** — 物語途中での新キャラクター追加、環境変化の注入
5. **エクスポート機能** — 生成した物語のPDF/EPUB出力

---

## さいごに

Living Taleは、「**書くのではなく、育てる**」という新しい創作パラダイムを提案するプロダクトです。

かつて「発信」はメディアや出版社の特権でした。それがnoteやSNSによって民主化されたように、**「物語を生み出すこと」もまた、すべての人に開かれるべき**だと私たちは考えています。

AIがクリエイターの仕事を奪うのではなく、**AIがクリエイターの「壁打ち相手」となり、想像を超える物語の種を提供する**。プロの漫画家や脚本家にとっては探索の加速器として、noteで文章を綴る人にとっては最初の一歩を支える伴走者として——そんな未来を、Gemini 2.0 Flashのマルチエージェント構成で実現しました。

テーマを1行入力するだけで、語り手AIが物語を紡ぎ、その裏側でキャラクターたちが語り手さえ知らない本音を独自に抱える——表と裏のズレが、予定調和を超えた物語体験を生み出します。ぜひ一度、体験してみてください。

🌐 https://living-tale-551115298648.us-central1.run.app/

最後まで読んでいただきありがとうございました！
質問やフィードバックは、ぜひ [GitHub](https://github.com/coralfish02/living-tale) のIssueまでお寄せください。

---

**チーム ADS'25** | [第4回 Agentic AI Hackathon with Google Cloud](https://zenn.dev/hackathons/google-cloud-japan-ai-hackathon-vol4) 参加作品
